{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Web of Lies - PDO Prompt Optimization\n",
        "\n",
        "This notebook demonstrates using **PDO (Prompt Duel Optimizer)** to optimize prompts for the Web of Lies logical reasoning task.\n",
        "\n",
        "## What is Web of Lies?\n",
        "\n",
        "Web of Lies is part of [**BIG-Bench Hard (BBH)**](https://github.com/suzgunmirac/BIG-Bench-Hard), a suite of 23 challenging tasks from BIG-Bench where language models previously failed to outperform average human-rater performance.\n",
        "\n",
        "The task tests logical reasoning by presenting chains of statements about people who either always tell the truth or always lie. The model must determine whether the final person in the chain tells the truth.\n",
        "\n",
        "**Example:**\n",
        "```\n",
        "Question: Sherrie tells the truth. Vernell says Sherrie tells the truth. \n",
        "Alexis says Vernell lies. Michaela says Alexis tells the truth. \n",
        "Elanor says Michaela tells the truth. Does Elanor tell the truth?\n",
        "\n",
        "Answer: No\n",
        "```\n",
        "\n",
        "**Citation:** Suzgun et al., 2022 - [Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them](https://arxiv.org/abs/2210.09261)\n",
        "\n",
        "## Quick Start\n",
        "\n",
        "1. **Set up your API key** - Create a `.env` file in the project root:\n",
        "   ```\n",
        "   OPENROUTER_API_KEY=your_api_key_here\n",
        "   ```\n",
        "\n",
        "2. **Run this notebook** to:\n",
        "   - Install prompt-ops in editable mode\n",
        "   - Load your OpenRouter credentials\n",
        "   - Run PDO optimization on the web_of_lies dataset\n",
        "   - Evaluate optimized vs baseline prompts\n",
        "\n",
        "## What is PDO?\n",
        "\n",
        "PDO uses dueling bandits and Thompson sampling to evolve prompts through competitive evaluation, automatically discovering which reasoning strategies work best.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install prompt-ops in editable mode (from project root)\n",
        "%pip install -U pip\n",
        "%pip install -e ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load OpenRouter API key from .env file\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Verify the API key is loaded\n",
        "api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
        "if api_key:\n",
        "    print(\"OPENROUTER_API_KEY loaded successfully (length):\", len(api_key))\n",
        "else:\n",
        "    print(\"WARNING: OPENROUTER_API_KEY not found in .env file\")\n",
        "    print(\"Please create a .env file in the project root with:\")\n",
        "    print(\"OPENROUTER_API_KEY=your_api_key_here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run PDO optimization on the Web of Lies task\n",
        "# This will optimize the prompt in prompts/prompt.txt using the config.yaml settings\n",
        "!prompt-ops migrate --config config.yaml --log-level INFO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Running the optimized prompt from the above module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimized_prompt='''Analyze the given statements about individuals telling the truth or lying, state assumptions about the truthfulness of each person based on the chain of statements, and determine the truthfulness of the last person mentioned in the question. For example, if Person A says Person B is lying and Person B says Person C is telling the truth, and it's given that Person A is lying, then Person B must be telling the truth, which means Person C is also telling the truth. Another example: if Person X claims Person Y is lying and Person Y says Person Z is truthful, but it's known that Person X is truthful, then Person Y is lying, and thus Person Z's truthfulness depends on the statement Person Y made about them. Apply this reasoning process to the given statements, as in the case where Person P says Person Q is lying, Person Q says Person R is telling the truth, and Person R says Person S is lying - determine the truthfulness of Person S based on the assumptions made about each person's statement.'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate PDO (optimized) and baselines (zero_shot, CoT, PoS) on web_of_lies.json\n",
        "import os, sys, json\n",
        "sys.path.append(os.path.abspath(\"../../src\"))\n",
        "\n",
        "from prompt_ops.core.pdo.meta_prompt import REASON_PROMPT, get_reason_schema\n",
        "from prompt_ops.core.model import setup_model\n",
        "\n",
        "# Load dataset from the current use case directory\n",
        "data_path = \"data/web_of_lies.json\"\n",
        "rows = json.load(open(data_path, \"r\"))\n",
        "gold = [r[\"answer\"].strip() for r in rows]\n",
        "answer_choices = [\"Yes\", \"No\"]\n",
        "answer_choices_str = \", \".join(answer_choices)\n",
        "\n",
        "# Model (match your optimization setup)\n",
        "model = setup_model(\n",
        "    adapter_type=\"litellm\",\n",
        "    model_name=\"openrouter/meta-llama/llama-3.3-70b-instruct\",\n",
        "    api_base=os.environ.get(\"OPENROUTER_API_BASE\", \"https://openrouter.ai/api/v1\"),\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "    max_tokens=4096,\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "def _parse_json(s: str):\n",
        "    try:\n",
        "        start = s.find(\"{\"); end = s.rfind(\"}\") + 1\n",
        "        blob = s[start:end] if (start >= 0 and end > start) else s\n",
        "        return json.loads(blob)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def evaluate_instruction(instruction_text: str) -> float:\n",
        "    prompts = [\n",
        "        REASON_PROMPT.format(\n",
        "            instruction=instruction_text,\n",
        "            question=r[\"input\"],\n",
        "            answer_choices_str=answer_choices_str,\n",
        "        )\n",
        "        for r in rows\n",
        "    ]\n",
        "    response_format = {\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"reasoned_answer\",\n",
        "            \"schema\": get_reason_schema(answer_choices),\n",
        "            \"strict\": True,\n",
        "        },\n",
        "    }\n",
        "    try:\n",
        "        preds_raw = model.generate_batch(\n",
        "            prompts, max_threads=4, temperature=0.0, response_format=response_format\n",
        "        )\n",
        "    except Exception:\n",
        "        preds_raw = model.generate_batch(prompts, max_threads=4, temperature=0.0)\n",
        "\n",
        "    pred = []\n",
        "    for s in preds_raw:\n",
        "        obj = _parse_json(s)\n",
        "        a = str(obj.get(\"answer\", \"\")).strip()\n",
        "        if not a:\n",
        "            a = answer_choices[0]  # fallback to first base choice\n",
        "        a = \"Yes\" if a.lower().startswith(\"y\") else \"No\" if a.lower().startswith(\"n\") else a\n",
        "        pred.append(a)\n",
        "\n",
        "    correct = sum(1 for p, g in zip(pred, gold) if p == g)\n",
        "    return correct / len(gold)\n",
        "\n",
        "STATIC_PROMPTS = {\n",
        "    \"No Prompt\": \"Answer the following question.\",\n",
        "    \"CoT\": \"Lets think step by step.\",\n",
        "    \"PoS\": \"First, devise a plan by breaking the problem into ordered subtasks. Then, based on that plan, solve each subtask and give the final answer.\",\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# PDO (optimized)\n",
        "\n",
        "print(\"\\nEvaluating PDO (optimized) prompt:\\n\", optimized_prompt)\n",
        "results['PDO'] = evaluate_instruction(optimized_prompt)\n",
        "\n",
        "# Baselines\n",
        "for name, instr in STATIC_PROMPTS.items():\n",
        "    print(f\"\\nEvaluating baseline '{name}' prompt:\\n\", instr)\n",
        "    results[name] = evaluate_instruction(instr)\n",
        "\n",
        "print(\"\\n=== Accuracy on web_of_lies ===\")\n",
        "if 'PDO' in results:\n",
        "    print(f\"PDO (optimized): {results['PDO']:.3f}\")\n",
        "for name in [\"No Prompt\",\"CoT\", \"PoS\"]:\n",
        "    if name in results:\n",
        "        print(f\"{name}: {results[name]:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama-prompt-ops",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
